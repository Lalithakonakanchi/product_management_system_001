import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def execute_full_pipeline(config):
    # 1. Configuration Setup
    input_file = config.get("input_file")
    x_col = config.get("x_axis")
    y_col = config.get("y_axis")
    pipeline = config.get("cleaning_pipeline", [])

    # Load Data
    df = pd.read_csv(input_file)
    print(f"Initial rows: {len(df)}")

    # 2. Sequential Execution
    for step in pipeline:
        method = step.get("method")
        sub_type = step.get("sub_type")
        params = step.get("params", {})

        print(f"Executing: {method} -> {sub_type}")

        # --- 1. HANDLING MISSING VALUES ---
        if method == "missing_values":
            if sub_type == "remove_rows":
                df = df.dropna(subset=[y_col]).reset_index(drop=True)
            elif sub_type == "interpolate":
                df[y_col] = df[y_col].interpolate(method=params.get("technique", "linear"), 
                                                  limit_direction=params.get("limit_direction", "both"))
            elif sub_type == "fill_mean":
                df[y_col] = df[y_col].fillna(df[y_col].mean())

        # --- 2. OUTLIER DETECTION AND REMOVAL ---
        elif method == "outlier_detection":
            if sub_type == "z_score_modified":
                threshold = params.get("threshold", 3)
                median_val = df[y_col].median()
                mad = np.median(np.abs(df[y_col] - median_val))
                if mad != 0:
                    modified_z = 0.6745 * (df[y_col] - median_val) / mad
                    df['is_outlier'] = np.abs(modified_z) > threshold
            elif sub_type == "iqr":
                multiplier = params.get("multiplier", 1.5)
                Q1 = df[y_col].quantile(0.25)
                Q3 = df[y_col].quantile(0.75)
                IQR = Q3 - Q1
                df['is_outlier'] = (df[y_col] < (Q1 - multiplier * IQR)) | (df[y_col] > (Q3 + multiplier * IQR))

        # --- 3. DATA TRANSFORMATION AND SCALING ---
        elif method == "transformation":
            if sub_type == "min_max_normalization":
                f_min, f_max = params.get("feature_range", [0, 1])
                y_min, y_max = df[y_col].min(), df[y_col].max()
                df[y_col] = f_min + (df[y_col] - y_min) * (f_max - f_min) / (y_max - y_min)
            elif sub_type == "standardization":
                df[y_col] = (df[y_col] - df[y_col].mean()) / df[y_col].std()
            elif sub_type == "log_transformation":
                df[y_col] = np.log1p(df[y_col])

        # --- 4. SMOOTHING AND NOISE REDUCTION ---
        elif method == "smoothing":
            w_size = params.get("window_size", 5)
            if sub_type == "moving_average":
                df[y_col] = df[y_col].rolling(window=w_size, min_periods=1, center=True).mean()
            elif sub_type == "exponential_smoothing":
                df[y_col] = df[y_col].ewm(span=w_size, adjust=False).mean()
            elif sub_type == "median_filter":
                df[y_col] = df[y_col].rolling(window=w_size, min_periods=1, center=True).median()

        # --- 5. DATA INTEGRITY AND DEDUPLICATION ---
        elif method == "data_integrity":
            if sub_type == "remove_duplicates":
                # CHANGE: Only removes rows where BOTH x_col and y_col are duplicates
                df = df.drop_duplicates(subset=[x_col, y_col]).reset_index(drop=True)
                print(f"Rows after duplicate removal: {len(df)}")
            elif sub_type == "sort_by_x":
                df = df.sort_values(by=x_col, ascending=params.get("ascending", True)).reset_index(drop=True)

    # --- FINAL VISUALIZATION ---
    plt.figure(figsize=(14, 7))
    plt.plot(df[x_col], df[y_col], color='blue', label='Processed Signal', alpha=0.7)
    
    if 'is_outlier' in df.columns:
        outliers = df[df['is_outlier'] == True]
        jitter = np.random.uniform(-0.5, 0.5, size=len(outliers))
        plt.scatter(outliers[x_col] + jitter, outliers[y_col], color='red', 
                    label='Detected Outliers', s=100, edgecolor='black', zorder=5)

    plt.title(f"Final Output: {y_col} vs {x_col}")
    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

    return df
user_config = {
  "input_file": "hppcoutput.csv",
  "x_axis": "expr_seq",
  "y_axis": "Voltage (V)",
  "cleaning_pipeline": [
    {"method": "data_integrity", "sub_type": "remove_duplicates", "params": {}}, # New step
    {"method": "data_integrity", "sub_type": "sort_by_x", "params": {"ascending": True}},
    {"method": "missing_values", "sub_type": "remove_rows", "params": {}},
    {"method": "outlier_detection", "sub_type": "iqr", "params": {"multiplier": 1.5}},
    {"method": "smoothing", "sub_type": "exponential_smoothing", "params": {"window_size": 5}},
    {"method": "transformation", "sub_type": "log_transformation", "params": {}}
  ]
}

final_df = execute_full_pipeline(user_config)
